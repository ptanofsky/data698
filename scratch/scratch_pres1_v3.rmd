---
title: "Predicting Citi Bike Availability in Brooklyn"
subtitle: |
  | DATA 698 Research Project
  | CUNY Fall 2022
author: "Philip Tanofsky"
date: "`r Sys.Date()`"
output:
  beamer_presentation:
    theme: "AnnArbor"
    colortheme: "default"
    fonttheme: "structurebold"
header-includes: \usepackage{subfig, graphicx}
classoption: t
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r libraries, echo=F, message=F, warning=F, include=F}
# Required packages
library(tidyverse)
library(ggplot2)
#library(skimr)
library(lubridate)
library(fpp3)
library(rgdal)
library(RColorBrewer)
library(jpeg)
library(data.table)
library(geosphere)
library(Metrics)
library(AER)
library(knitr)
library(MASS)
library(pscl)
library(RANN)
library(kableExtra)
#library(broom)

```

## Citi Bike Availability

Predict bike availability to avoid the empty racks

\begin{figure}
  \centering
  \includegraphics[width=0.35\textwidth, height=\textheight, keepaspectratio]{cb_empty_rack_01.JPG}\hfil
  \includegraphics[width=0.35\textwidth, height=\textheight, keepaspectratio]{cb_empty_rack_02.JPG} 

  \includegraphics[width=0.35\textwidth, height=\textheight, keepaspectratio]{cb_empty_rack_03.JPG}\hfil   
  \includegraphics[width=0.35\textwidth, height=\textheight, keepaspectratio]{cb_empty_rack_04.JPG}
\end{figure}

## Problem and Objectives

Problem

- Citi Bike offers live map of availability and the Lyft app provides real-time availability for immediate bike rental but the availability of a bike at a location at a future date and time is not guaranteed

Objectives:

- Understand Citi Bike usage and availability patterns across New York City

- Predict the number of available bikes in Brooklyn within a quarter mile of a given location with user-friendly inputs


## Previous Work

- Wang, Lindsey, Schoner, and Harrison (2016)
  - Log-linear and negative binomial regression models
- Wang and Chen 
  - Zero-inflated negative binomial regression model
- Hyland, Hong, Pinto and Chen
  - Hybrid clustering and regression models
- MÃ©dard de Chardon, Caruso, and Thomas
  - Rebalancing evaluation
  
## Data Collection

Citi Bike System Data

- Download CSV files for each month
- API call every 15 minutes for two weeks

NYC Open Data

- Borough shapes via GeoJSON files

Docking Station Elevation

- R library `elevatr`

Surplus/Shortage Timetable

- Convert trip data to dataframe of bike departure and arrival counts by docking station for a given time interval

## Data Statistics

Ridership patterns

  - Timeframe: August - October of 2022 (92 days)
  - Location: New York City departing trips
  - Number of trips: 10,210,102
  - Docking Stations: 1,717
  - Abandoned trips: 24,887

Bike Availability

  - Timeframe: Oct. 31 - Nov. 13 of 2022 (14 days)
  - Location: Brooklyn
  - Docking Stations: 474
  
## Challenges

Large volume of data

- Over 10 million trips in 3 months
- Over 1700 docking stations in NYC

Rebalancing

- System action of moving bikes to restock docking stations
- Identification and inconsistency

User-friendly availability prediction

- Independent variables to prediction model
- End-user input values

## EDA: Bike Trips by Hour

```{r read.trip.data, echo=F, message=F, warning=F, include=F, eval=T}
# Create additional columns of pertinence
# weekday, day of the month, trip duration in minutes, start hour
#citibike_202208 <- fread("data/202208-citibike-tripdata.csv", data.table=FALSE, check.names=TRUE)
#citibike_202209 <- fread("data/202209-citibike-tripdata.csv", data.table=FALSE, check.names=TRUE)
#citibike_202210 <- fread("data/202210-citibike-tripdata.csv", data.table=FALSE, check.names=TRUE) %>%

citibike <- fread("data/202210-citibike-tripdata.csv", data.table=FALSE, check.names=TRUE) %>%
#citibike <- bind_rows(citibike_202208, citibike_202209, citibike_202210) %>%
  mutate(day = factor(mday(ymd_hms(started_at))),
         start.hour=factor(hour(ymd_hms(started_at))),
         weekday = lubridate::wday(ymd_hms(started_at), label=TRUE, abbr=TRUE),
         trip.duration = as.numeric(difftime(ended_at,started_at,units="mins")),
         member_casual = factor(member_casual)) %>%
  rename(ride.id=ride_id, rideable.type=rideable_type, started.at=started_at,
         ended.at=ended_at, start.station.name=start_station_name, start.station.id=start_station_id,
         end.station.name=end_station_name, end.station.id=end_station_id, start.lat=start_lat,
         start.lng=start_lng, end.lat=end_lat, end.lng=end_lng, member.casual=member_casual)

# Figure out abandoned and label them
citibike$end.station.name[citibike$end.station.name == ''] <- "Abandoned"
citibike$end.station.id[citibike$end.station.id  == ''] <- "ABAN"

# Output DF if needed
head(citibike)
```

Bike Trips by Hour by User Type for Aug. - Oct. 2022

```{r trip.by.hour.time.series, echo=F, message=F, warning=F, include=T, fig.height=5}

citibike$started.at.ts <- as_datetime(as.character(citibike$started.at))

citibike_by_hour <- citibike %>%
  mutate(hour=lubridate::floor_date(started.at.ts, "1 hour")) %>%
  group_by(hour, member.casual) %>%
  summarize(cnt=n())
#citibike_by_hour

citibike_by_hour_ts <- citibike_by_hour %>%
  as_tsibble(index=hour, key=c(member.casual))
#citibike_by_hour_ts

autoplot(citibike_by_hour_ts, cnt) +
  labs(x = "Time by Hour",
       y = "Ride Trip Counts") +
  guides(colour = guide_legend(title = "User Type")
        )

```


## EDA: Weekly Seasonal Pattern

Weekly seasonal plot of the bike trips for Aug. - Oct. 2022

```{r trip.by.hour.seasonal, echo=F, message=F, warning=F, include=T, fig.height=5}
citibike_by_hour_ts %>%
  gg_season(cnt, period = "week") +
  labs(x = "Time",
       y = "Bike Trips")
```

## EDA: Three-Month Summary

System-wide view of surplus or shortage for every NYC docking station

::: columns

:::: column

\begin{center}
  \includegraphics[trim={0 0 5cm 0},clip]{stations_surplus_sum.jpg}
\end{center}

::::

:::: column

Docking Station Color

- Blue: Surplus
- Red: Shortage
- Green: Even

::::

:::

## EDA: Daily Pattern

Time lapse of surplus or shortage for every NYC docking station

\begin{figure}
  \centering
  \subfloat[5 a.m.]{\includegraphics[width=3cm]{cb_stations_surplus_5A.jpg}}\hfil
  \subfloat[8 a.m.]{\includegraphics[width=3cm]{cb_stations_surplus_8A.jpg}}\hfil 
  \subfloat[11 a.m.]{\includegraphics[width=3cm]{cb_stations_surplus_11A.jpg}} 

  \subfloat[2 p.m.]{\includegraphics[width=3cm]{cb_stations_surplus_2P.jpg}}\hfil   
  \subfloat[5 p.m.]{\includegraphics[width=3cm]{cb_stations_surplus_5P.jpg}}\hfil
  \subfloat[8 p.m.]{\includegraphics[width=3cm]{cb_stations_surplus_8P.jpg}}
  \caption{Average Wednesday}
\end{figure}


## Overview of Algorithm Approach

Goal: Predict number of available  bikes in Brooklyn within quarter mile

Inputs

- Latitude and longitude (location on map)
- Day of the Week
- Time of Day

Step 1: Hierarchical Clustering

- Cluster all the Brooklyn docking stations
  - Distance: 400m (Quarter mile)
  
Step 2: Apply Generalized Linear Models

- Predict number of bikes available per cluster
  - Count Models: Poisson, Negative Binomial, Zero-Inflated


## Stations with Zero Bike Availability

Frequency of zero bikes available per docking station in Brooklyn

- Span: Two weeks
- Instance: 15-minute interval

\begin{center}
  \includegraphics[width=0.5\textwidth, height=\textheight, keepaspectratio]{bk_stations_zero_avail.jpg}
\end{center}


## Rebalancing Example

Inconsistent bike availability at Docking Station 3582 in Brooklyn

```{r display.station.reblance, echo=F, message=F, warning=F, include=T, fig.height=5}
citibike_bike_avail <- fread("bike_avail_by_station_and_time.csv", data.table=FALSE, check.names=FALSE)

citibike_bike_avail <- citibike_bike_avail %>%
  dplyr::select(-V1)

citibike_bike_avail_long <- citibike_bike_avail %>%
  pivot_longer(!timestamp, names_to = "station.id", values_to = "bikes.avail")


citibike_bike_avail_long_trim <- citibike_bike_avail_long %>%
  filter(as.integer(station.id) == 3582)

p_rebalance_station <- ggplot(citibike_bike_avail_long_trim, 
                              aes(x=timestamp, y=bikes.avail, group=station.id)) + 
  geom_line(aes(color=station.id), show.legend = FALSE) +
  geom_point(aes(color=station.id), show.legend = FALSE) +
    labs(x='Time',
         y='Available Bikes')

p_rebalance_station
```

## Proposed Methodologies

Predictors

- Latitude and longitude converted to cluster
- Day of the Week converted to 'Weekday' or 'Weekend'
- Time of Day in 1-hour intervals
- Average elevation of cluster omitted

Model Methodologies

- Selected: Generalized Linear Model for Counts
  - Poisson Regression Assumptions:
    - Response variable is count per unit of time
    - Independence: Observations are independent in nature
    - Mean equal to Variance: Not true

- Alternate Consideration: Time Series Model
  - Forecasting does not provide instance prediction
  - Not easily translatable from user-friendly inputs
  - Requires constantly up-to-date info to forecast from given point in time


## Modeling Step 1: Clustering Model

- Borough: Brooklyn
- Docking Stations: 474
- Clusters: 213 (2.23 stations/cluster)

\begin{center}
  \includegraphics[width=0.5\textwidth, height=\textheight, keepaspectratio]{bk_stations_by_cluster.jpg}
\end{center}


## Bike Availability Count Frequency

Histogram of availability based on 1HR intervals for Brooklyn clusters

- High frequency near 0 and 2 and plateaus at docking station capacities

```{r display.bk.freqOfZero.by.cluster, echo=F, message=F, warning=F, include=T, fig.height=5}
# Read in the csv of the API responses which have been wrangled together
stations_with_bike_avail <- read.csv('bike_avail_by_station_and_time.csv', row.names = 1, header= TRUE, check.names = FALSE)

stations_with_bike_avail_long <- stations_with_bike_avail %>%
  pivot_longer(!timestamp, names_to = "station.id", values_to = "bikes.avail.count")

stations_with_elevation <- read.csv('stations_with_elevation.csv', row.names = 1, header= TRUE)

stations_with_boro_hood <- read.csv('stations_with_boro_and_hood.csv', row.names = 1, header= TRUE)

# Combine the elevation, borough, neighborhood, and September surplus
# First let's trim the DF for elevation
stations_with_elevation_trim <- stations_with_elevation %>%
  dplyr::select(short_name, station_id, elevation, elev_units)

stations_with_boro_hood_trim <- stations_with_boro_hood %>%
  dplyr::select(short_name, name, station_id, capacity, ntaname, boro_name, lon, lat)

stations_attrs_trim <- 
  merge(stations_with_elevation_trim, 
        stations_with_boro_hood_trim, 
        by.x=c('short_name'), 
        by.y=c('short_name'), all = TRUE)

stations_attrs_trim <- stations_attrs_trim %>%
  dplyr::select(-station_id.y)

colnames(stations_attrs_trim)[colnames(stations_attrs_trim) == 'station_id.x'] <- 'station_id'

stations_attrs_trim[c("boro_name")][is.na(stations_attrs_trim[c("boro_name")])] <- "New Jersey"

stations_attrs_trim <- 
  stations_attrs_trim %>% 
  mutate(ntaname = ifelse(startsWith(short_name, "JC"), "Jersey City", ntaname))

stations_attrs_trim <- 
  stations_attrs_trim %>% 
  mutate(ntaname = ifelse(startsWith(short_name, "HB"), "Hoboken", ntaname))

stations_attrs_trim <- stations_attrs_trim %>%
  rename(short.name=short_name, station.id=station_id, elev.units=elev_units, nta.name=ntaname, boro.name=boro_name)

stations_attrs_trim_bk <- stations_attrs_trim %>%
  filter(boro.name == "Brooklyn")

# Distance matrix for docking stations
# Result is in meters
dist_mat <- distm(stations_attrs_trim_bk[9:10], stations_attrs_trim_bk[9:10], fun=distHaversine)
dist_mat <- as.data.frame(dist_mat)

dist_mat[is.na(dist_mat)] <- 0
dMat <- as.dist(dist_mat)

# Now for the clustering
hier_clust <- hclust(dMat, method = "complete")
# 400 meters is about a quarter of a mile (0.248548 miles)
stations_attrs_trim_bk$cluster <- cutree(hier_clust, h=400)

station_to_cluster <- stations_attrs_trim_bk %>%
  dplyr::select(station.id, cluster, elevation, capacity)

# Merge long df with counts with station.id and cluster to label clusters properly
stations_bike_avail_by_time <- 
  merge(stations_with_bike_avail_long, 
        station_to_cluster, 
        by.x=c('station.id'), 
        by.y=c('station.id'), all.x = TRUE)

stations_bike_avail_by_time_no_na <- stations_bike_avail_by_time %>%
  filter(!is.na(cluster))

stations_bike_avail_by_time_no_na_group_sum <- stations_bike_avail_by_time_no_na %>%
  group_by(timestamp, cluster) %>%
  summarize_at(vars(bikes.avail.count, capacity), sum)

stations_bike_avail_by_time_no_na_group_mean <- stations_bike_avail_by_time_no_na %>%
  group_by(timestamp, cluster) %>%
  summarise_at(vars(elevation), mean)

stations_bike_avail_by_time_no_na_group <- cbind(stations_bike_avail_by_time_no_na_group_sum, stations_bike_avail_by_time_no_na_group_mean[3])

# mutate to convert timestamp into day of the week, etc.
stations_bike_avail_by_time_no_na_group <- stations_bike_avail_by_time_no_na_group %>%
  mutate(time=as.ITime(ymd_hms(timestamp)),
         weekday = lubridate::wday(ymd_hms(timestamp),label=TRUE,abbr=TRUE))

stations_bike_avail_by_time_no_na_group$cluster <- as.factor(stations_bike_avail_by_time_no_na_group$cluster)
stations_bike_avail_by_time_no_na_group$time <- as.factor(stations_bike_avail_by_time_no_na_group$time)
stations_bike_avail_by_time_no_na_group$weekday <- factor(stations_bike_avail_by_time_no_na_group$weekday, ordered=FALSE)

stations_bike_avail_by_time_no_timestamp <- subset(stations_bike_avail_by_time_no_na_group, select=-c(timestamp))

stations_bike_avail_by_time_1H <- stations_bike_avail_by_time_no_timestamp %>%
  filter(endsWith(as.character(time), "00:00"))

stations_bike_avail_by_time_1H <- stations_bike_avail_by_time_1H %>%
  mutate(day = ifelse(weekday %in% c('Sat', 'Sun'), 'WKND', 'WDAY'))


# Table of availability based on 1HR intervals
tab_1H <- table(stations_bike_avail_by_time_1H$bikes.avail.count)

# This plot shows the available bike count frequencies given 1HR intervals and Brooklyn station clusters for the 2 weeks. 0 is the most frequent count and filterd at 150, just to provide some sort of upper bound

# There appears to be a max around 22 or so as the distribution drops off just before 25, likely a result of docking station capacity

tab_1H_df <- as.data.frame(tab_1H)

tab_1H_df$Var1 <- as.integer(tab_1H_df$Var1)

# Distrbution of count results
p_distro_avail_counts <- tab_1H_df %>%
  filter(Var1 < 150) %>%
  ggplot(aes(x=Var1, y=Freq)) +
  geom_bar(stat="identity") +
  labs(x='Availability Count',
       y='Frequency')
#  title='Frequency of Hourly Available Bike Counts for Brooklyn Clusters'

# Display plot
p_distro_avail_counts
```


## Modeling Step 2: Count Models

Generalized Linear Models for Count Data

5 Models Attempted

- Poisson
  - `stats` library
- Quasi-Poisson
  - `stats` library
- Negative Binomial
  - `MASS` library
- Zero-Inflated
  - Poisson and Negative Binomial
  - `pscl` library
  

```{r}
stations_bike_avail_by_time_1H_imp <- stations_bike_avail_by_time_1H


#71568 rows total in the train set
#2992 in which the bikes.avail.count greater than capacity
#125 clusters have avail greater than capacity

# Impute the available bike count to match the capacity
stations_bike_avail_by_time_1H_imp$bikes.avail.count <- ifelse(stations_bike_avail_by_time_1H_imp$bikes.avail.count >
                                                        stations_bike_avail_by_time_1H_imp$capacity,
                                                      stations_bike_avail_by_time_1H_imp$capacity,
                                                      stations_bike_avail_by_time_1H_imp$bikes.avail.count)
```


## Model Results 1-Hour Interval

- Certain input to model based on 1 hour intervals below
- Results table

```{r models.1H.intervals, eval=T, echo=F, message=F, warning=F, include=T}
#stations_bike_avail_by_time_1H <- stations_bike_avail_by_time_no_timestamp %>%
#  filter(endsWith(as.character(time), "00:00"))

# Start with data partition here.
set.seed(8675309)
index <- sample(2, nrow(stations_bike_avail_by_time_1H_imp), replace = TRUE, p=c(0.75, 0.25))
#index <- sample(2, nrow(stations_bike_avail_by_time_1H), replace = TRUE, p=c(0.75, 0.25))
train_1H <- stations_bike_avail_by_time_1H[index==1,]
test_1H <- stations_bike_avail_by_time_1H[index==2,]

# Sample Variance is 313
var(stations_bike_avail_by_time_1H$bikes.avail.count)
n <- length(stations_bike_avail_by_time_1H)
# Population variance
var(stations_bike_avail_by_time_1H$bikes.avail.count)*(n-1)/n
# Mean is 13
mean(stations_bike_avail_by_time_1H$bikes.avail.count)

# Overdispersion exists

mod_1H_pois <- glm(bikes.avail.count ~ cluster + time + day, data = train_1H, family ="poisson")
#summary(mod_1H_pois)

#dispersiontest(mod_1H_pois)

# Taking the floor as that is the actual available bikes, no partial bikes
pred_1H_pois <- predict.glm(mod_1H_pois, newdata = test_1H, type = "response")
rmse_mod_1H_pois <- ModelMetrics::rmse(test_1H$bikes.avail.count,floor(pred_1H_pois))
mae_mod_1H_pois <- mae(test_1H$bikes.avail.count,floor(pred_1H_pois))

mod_1H_qp <- glm(bikes.avail.count ~ cluster + time + day, data = train_1H, family ="quasipoisson")
#summary(mod_1H_qp)

pred_1H_qp <- predict.glm(mod_1H_qp, newdata=test_1H, type = "response")
rmse_mod_1H_qp <- ModelMetrics::rmse(test_1H$bikes.avail.count,floor(pred_1H_qp))
mae_mod_1H_qp <- mae(test_1H$bikes.avail.count,floor(pred_1H_qp))

mod_1H_nb <- glm.nb(bikes.avail.count ~ cluster + time + day, data=train_1H)
#summary(mod_1H_nb)

pred_1H_nb <- predict.glm(mod_1H_nb, newdata=test_1H, type = "response")
rmse_mod_1H_nb <- ModelMetrics::rmse(test_1H$bikes.avail.count,floor(pred_1H_nb))
mae_mod_1H_nb <- mae(test_1H$bikes.avail.count,floor(pred_1H_nb))

mod_1H_zero_pois <- zeroinfl(bikes.avail.count ~ cluster + time + day, data=train_1H, dist = "poisson")
#summary(mod_1H_zero_pois)

pred_1H_zero_pois <- predict(mod_1H_zero_pois, newdata=test_1H,type = "response")
rmse_mod_1H_zero_pois <- ModelMetrics::rmse(test_1H$bikes.avail.count,floor(pred_1H_zero_pois))
mae_mod_1H_zero_pois <- mae(test_1H$bikes.avail.count,floor(pred_1H_zero_pois))

mod_1H_zero_nb <- zeroinfl(bikes.avail.count ~ cluster + time + day, data=train_1H,dist = "negbin")
#summary(mod_1H_zero_nb)

pred_1H_zero_nb <- predict(mod_1H_zero_nb, newdata=test_1H ,type = "response")
rmse_mod_1H_zero_nb <- ModelMetrics::rmse(test_1H$bikes.avail.count,floor(pred_1H_zero_nb))
mae_mod_1H_zero_nb <- mae(test_1H$bikes.avail.count,floor(pred_1H_zero_nb))

# Hurdle
#mod_1H_hurd_pois <- hurdle(bikes.avail.count ~ cluster + time + day, data=train_1H, dist = "poisson")
#summary(mod_1H_hurd_pois)

#pred_1H_hurd_pois <- predict(mod_1H_hurd_pois, newdata=test_1H, type = "response")
#rmse_mod_1H_hurd_pois < -ModelMetrics::rmse(test_1H$bikes.avail.count,floor(pred_1H_hurd_pois))
#mae_mod_1H_hurd_pois <- mae(test_1H$bikes.avail.count,floor(pred_1H_hurd_pois))

rmse_1H <- c(rmse_mod_1H_pois, rmse_mod_1H_qp, rmse_mod_1H_nb,
#             rmse_mod_1H_hur_pois, rmse_mod_1H_hu_nb,
             rmse_mod_1H_zero_pois, rmse_mod_1H_zero_nb)
mae_1H <- c(mae_mod_1H_pois, mae_mod_1H_qp, mae_mod_1H_nb,
#            mae_mod_1H_hur_pois, mae_mod_1H_qp,
            mae_mod_1H_zero_pois, mae_mod_1H_zero_nb)

aic_1H <- c(mod_1H_pois$aic, mod_1H_qp$aic, mod_1H_nb$aic,
#            mae_mod_1H_hur_pois, mae_mod_1H_qp,
            mod_1H_zero_pois$loglik, mod_1H_zero_nb$loglik)

models_1H <- c("Poisson","Quasi-Poisson","Negative Binomial",
#               "h_pois","h_nb",
               "Zero (Poisson)","Zero (Neg. Binomial)")

#data.frame(models_1H, rmse_1H, mae_1H)%>% 
#  arrange(rmse_1H)
```

```{r model.preds.dataframe, eval=T, echo=F, message=F, warning=F, include=F}
df_for_plot <- as.data.frame(cbind(test_1H, 
                                   floor(pred_1H_pois),
                                   floor(pred_1H_qp),
                                   floor(pred_1H_nb),
                                   floor(pred_1H_zero_pois),
                                   floor(pred_1H_zero_nb))) %>%
  rename(Actual='bikes.avail.count', Pois.Prediction=8, QPois.Prediction=9, 
         NB.Prediction=10, Zero.Pois.Prediction=11, Zero.NB.Prediction=12)

df_for_plot$Actual <- as.integer(df_for_plot$Actual)
df_for_plot$Pois.Prediction <- as.integer(df_for_plot$Pois.Prediction)
df_for_plot$QPois.Prediction <- as.integer(df_for_plot$QPois.Prediction)
df_for_plot$NB.Prediction <- as.integer(df_for_plot$NB.Prediction)
df_for_plot$Zero.Pois.Prediction <- as.integer(df_for_plot$Zero.Pois.Prediction)
df_for_plot$Zero.NB.Prediction <- as.integer(df_for_plot$Zero.NB.Prediction)

miss_zero_pois <- df_for_plot %>%
  filter(Pois.Prediction > 0 & Actual == 0) %>%
  count()
miss_zero_qp <- df_for_plot %>%
  filter(QPois.Prediction > 0 & Actual == 0) %>%
  count()
miss_zero_nb <- df_for_plot %>%
  filter(NB.Prediction > 0 & Actual == 0) %>%
  count()
miss_zero_z_p <- df_for_plot %>%
  filter(Zero.Pois.Prediction > 0 & Actual == 0) %>%
  count()
miss_zero_z_nb <- df_for_plot %>%
  filter(Zero.NB.Prediction > 0 & Actual == 0) %>%
  count()

miss_zero_1H <- c(miss_zero_pois, miss_zero_qp, miss_zero_nb,
            miss_zero_z_p, miss_zero_z_nb)
```

```{r table.model.results, eval=T, echo=F, message=F, warning=F, include=T}
data.frame(Model=models_1H, RMSE=rmse_1H, MAE=mae_1H, `Missed Zero`=miss_zero_1H) %>% 
  arrange(rmse_1H) %>% kable() %>%
  kable_paper("hover", full_width = F)
```

17715 rows for Prediction vs Actual

Poisson and QP predicted a higher number of Zero compared to Zero inflated, but because the zero is in line with the overall distribution, shouldn't be too surprised.

Zero Poisson with floor
(Prediction>0 & Actual==0) is 280
Zero NB
(Prediction>0 & Actual==0) is 280
Poisson
(Prediction>0 & Actual==0) is 263
QP
(Prediction>0 & Actual==0) is 263
NB
(Prediction>0 & Actual==0) is 263

Hurdle Poisson with floor
(Prediction>0 & Actual==0) is 282



397 rows in which actual availability is zero
Zero Pois

8 Clusters have a Prediction > 0 but Actual of 0 with basic Poisson model

- Poisson regression equation

\begin{equation} 
log(bikes) = \alpha + \beta_1\cdot cluster + \beta_2 \cdot time + \beta_3 \cdot day
\end{equation} 

Criteria, overall each model works well, but the Poisson has the highest number of predicted Zeros and slighter lower count of Prediction greater than 0 while the Actual is 0. Given this would be the frustrating for user, primary deciding criteria is the ability to predict 0 with accuracy

58 cluster coefficients greater than zero
154 clusters with coefficient less than zero

7 time coefficients with value greater than zero (morning times)
16 time coefficients with value less than zero

1 day coefficient less than zero (weekend)


## Model Results Visualization

Plot subset of Predicted vs Actual counts for select model - Poisson

- Blue: Prediction; Red: Actual

```{r display.top.model.preds, eval=T, echo=F, message=F, warning=F, include=T, fig.height=5}
# Modify the number of rows to consider
# 17715 rows in DF
df_for_plot_trim <- df_for_plot[500:600,]

p_pred_vs_actual <- ggplot() + 
  geom_line(data = df_for_plot_trim, aes(x = 1:nrow(df_for_plot_trim), y = Pois.Prediction), color = "blue") +
  geom_line(data = df_for_plot_trim, aes(x = 1:nrow(df_for_plot_trim), y = Actual), color = "red") +
  xlab('Sample Index') +
  ylab('Available Bike Count')

p_pred_vs_actual
```


## Availability Prediction

Model prediction inputs

- Longitude and Latitude (GPS location of smartphone)
- Hour of the day (dropdown proposed)
- Weekday or Weekend (dropdown proposed)

```{r prediction.function.signature, eval=T, echo=F, message=F, warning=F, include=T}
predict_num_bikes_avail <- function(longitude, latitude, time, day) {}
```
  
```{r prediction.function, eval=T, echo=F, message=F, warning=F, include=T}
predict_num_bikes_avail <- function(longitude, latitude, time, day) {
  #longitude: -73.960859 (in Brooklyn with quarter mile of docking station)
  #latitude: 40.67355 (in Brooklyn with quarter mile of docking station)
  #time: "00:00:00"|"01:00:00"|"02:00:00"|"03:00:00"|"04:00:00"|"05:00:00"|
  #      "06:00:00"|"07:00:00"|"08:00:00"|"09:00:00"|"10:00:00"|"11:00:00"|
  #      "12:00:00"|"13:00:00"|"14:00:00"|"15:00:00"|"16:00:00"|"17:00:00"|
  #      "18:00:00"|"19:00:00"|"20:00:00"|"21:00:00"|"22:00:00"|"23:00:00"|
  #day: "WKND"|"WDAY"
  
  # Convert lon/lat to cluster
  location <- data.frame(matrix(nrow = 1,data = c(longitude, latitude)))
  closest_station <- nn2(stations_attrs_trim_bk[, 9:10], query=location, k=1)
  inp_cluster <- stations_attrs_trim_bk[closest_station$nn.idx,]$cluster

  #print(inp_cluster)
  
  # Create input for prediction
  bike_avail_query <- data.frame(matrix(nrow = 1, data = c(inp_cluster, 0, time, day)))
  colnames(bike_avail_query) <- c("cluster", "bikes.avail.count", "time", "day")

  # Predict using Model: mod1
  num_bikes_avail <- predict(mod_1H_zero_pois, newdata = bike_avail_query, type = "response")
  # Take floor of prediction to ensure whole number
  num_bikes_avail <- as.integer(floor(num_bikes_avail))
  
  return(c(num_bikes_avail, inp_cluster))
}
```

```{r prediction.one, eval=T, echo=F, message=F, warning=F, include=T}
# Crown Heights
prediction_CH <- predict_num_bikes_avail(-73.960859, 40.67355,
                        "22:00:00", "WDAY")

print(paste0("Crown Heights - Available Bikes: ", prediction_CH[1], "; Cluster: ", prediction_CH[2]))
```

```{r prediction.two, eval=T, echo=F, message=F, warning=F, include=T}
# Williamsburg
prediction02_WB <- predict_num_bikes_avail(-73.9617, 40.7192,
                        "18:00:00", "WKND")

print(paste0("Williamsburg - Available Bikes: ", prediction02_WB[1], "; Cluster: ", prediction02_WB[2]))
```

```{r prediction.three, eval=T, echo=F, message=F, warning=F, include=T}
# Sunset Park
prediction02_SP <- predict_num_bikes_avail(-74.00509, 40.64338,
                        "17:00:00", "WDAY")

print(paste0("Sunset Park - Available Bikes: ", prediction02_SP[1], "; Cluster: ", prediction02_SP[2]))
```

## Current Achievements

Bike Availability prediction model for Brooklyn

- Hierarchical clustering
  - Location-based
- Poisson Model 
  - Simplest count model
  - Better predictor of zero availability

Ridership usage patterns

- Capture patterns of Citi Bike usage
  - System wide evaluation of NYC
  - Weekly and daily bike trip patterns

## Future Works

- Deploy web application or smartphone app to use GPS location
- Model of all New York City
- Real-time clustering to ensure all docking stations within quarter-mile of user
- Increase amount of availability data

