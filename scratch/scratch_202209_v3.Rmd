---
title: "Scratch with Sept 2022 Data"
author: "Philip Tanofsky"
date: "`r Sys.Date()`"
output: html_document
---

Scratch work using the September 2022 data, most recent as I'm working on this Oct. 30, 2022

Update: v2, started working at 8:30p on Friday, Nov. 11, 2022

Updated: v3, started working at 1:44P on Saturday, Nov. 12, 2022


11/12/2022

Data Collection and Analysis




```{r warning=FALSE}
# Required packages
library(tidyverse)
library(ggplot2)
library(skimr)
#library(tidyjson)
#library(geosphere)
library(lubridate)
# library(ggmap)
#library(forcats)
#library(scales)
```


Analysis starting with the Citibike bike trips for September 2022.

```{r}
# Let's create some other columns of value
# weekday, day of the month, trip duration in minutes, start hour
citibike <- read.csv("data/202209-citibike-tripdata.csv", check.names=TRUE) %>%
  mutate(day = factor(mday(ymd_hms(started_at))),
         start.hour=factor(hour(ymd_hms(started_at))),
         weekday = wday(ymd_hms(started_at),label=TRUE,abbr=TRUE),
         trip.duration = as.numeric(difftime(ended_at,started_at,units="mins")),
         member_casual = factor(member_casual))

#citibike
```

Columns
- ride_id: Unique identifier of the ride

- rideable_type: class vs electric bike

- started_at: Timestamp of trip start

- ended_at: Timestamp of trip end

- start_station_name: Name of station of trip departure

- start_station_id: Unique identifier of station of trip departure

- end_station_name: Name of station of trip arrival

- end_station_id: Unique identifier of station of trip arrival

- start_lat: Latitude of departure location

- start_lng: Longitude of departure location

- end_lat: Latitude of arrival location

- end_lng: Longitude of arrival location

- member_casual: Member or casual user type

- day: Day of the month

- start.hour: Hour of the trip departure

- weekday: Day of the week for the trip

- trip.duration: Duration of bike trip in minutes.

```{r}
citibike
```

September contains 3,507,123 rows, so 3.5 million trips during the month of September 2022.

```{r}
skim(citibike)
```

3507123 ride_id's which is one for each bike trip

- rideable_type: classic_bike which is pedal, electric_bike which is electric and docked_bike which is ???

I w


From: https://ride.citibikenyc.com/system-data

This data has been processed to remove trips that are taken by staff as they service and inspect the system, trips that are taken to/from any of our “test” stations (which we were using more in June and July 2013), and any trips that were below 60 seconds in length (potentially false starts or users trying to re-dock a bike to ensure it's secure).

```{r}
citibike %>%
  group_by(rideable_type) %>%
  summarize(n=n())
```

Docked_bike is 28432 which is almost 1000 per day, does this represent the rebalancing?

```{r}
citibike %>%
  filter(rideable_type=='docked_bike') %>%
  group_by(member_casual) %>%
  summarize(n=n())
```
All 28432 are casual for the 'docked_bike'

```{r}
citibike %>%
  filter(is.na(end_lat))
```

It appears 3838 bike trips were abandoned as the end_lat, end_long, end_station_name, and end_station_id are empty.

```{r}
# Number of trips for each hour of the day
ggplot(citibike, aes(x=start.hour)) +
  geom_bar() +
  labs(x = 'Time of Day',
       y = 'Number of Trips') +
  theme(axis.text.x = element_text(size=8, angle=90))

```

This is overall user base, so a spike at 8a and then again at 5p and 6p hour, which is expected for rush hour, to and from work.

```{r}
# Now let's check trips per hour by user type
ggplot(citibike, aes(x=start.hour)) +
  geom_bar() +
  labs(x = 'Time of Day',
       y = 'Number of Trips') +
  theme(axis.text.x=element_text(size=8, angle=90)) +
  facet_wrap(~member_casual)
```

Rush hour spikes for members, also a bit of a evening rush hour for casual, too. The separation of member vs casual shows a clearer spike at the rush hour times

```{r}
# Trips by weekday, total count
ggplot(citibike, aes(x=weekday)) +
  geom_bar() +
  labs(x = 'Day of Week',
       y = 'Number of Trips',
       title = 'Number of Bike Trips by Day of Week')
```

Greater on Thu and Friday, but is that due to extra days of the month ... I bet it is.

```{r}
citibike %>%
  group_by(day) %>%
  summarize(n=n(),
            weekday = weekday[1]) %>%
  group_by(weekday) %>%
  summarize(n.m=mean(n)) %>% # Get the average for each day to account for extra days of the month beyond 28
  ggplot(aes(x=weekday, y=n.m)) + geom_bar(stat='identity') +
  labs(x = 'Day of Week',
       y = 'Number of Trips',
       title = 'Average Number of Bike Trips by Day of Week')
```

Yep, that lowers the Thu and Fri count. And now it appears Wed is the highest volume day

```{r}
# Let's check the volume of day by the user type
citibike %>%
  group_by(day, member_casual) %>%
  summarize(n=n(),
            weekday = weekday[1]) %>%
  group_by(weekday, member_casual) %>%
  summarize(n.m=mean(n)) %>%
  ggplot(aes(x=weekday, y=n.m)) + geom_bar(stat='identity') +
  labs(x = 'Day of Week',
       y = 'Number of Trips',
       title = 'Number of Bike Trips by Day of Week') +
  facet_wrap(~member_casual)
```

Casual is more likely tourists and recreation use, while member are more likely to use during weekdays, and thus more likely for work

```{r}
# Trip by weekday by segment by time of day
citibike %>%
  group_by(day, member_casual, start.hour) %>%
  summarize(n=n(),
            weekday=weekday[1]) %>%
  group_by(weekday, member_casual, start.hour) %>%
  summarize(n.m=mean(n)) %>%
  ggplot(aes(x=start.hour, y=n.m, fill=weekday)) +
  geom_bar(stat='identity') +
  labs(x='Time of Day',
       y='Number of Trips',
       title='Average Number of Bike Trips by Time of Day and Weekday') +
  facet_grid(weekday~member_casual) +
  theme(axis.text.x = element_text(size=8, angle=90),
        legend.position = 'none')
```

Here, we see member accounts use the bikes on the weekend greater than casual. Interesting, for casual we do see spikes during the end of workday rush hour on Tue, Wed, Thu, Fri.

```{r}
# Trip durations
# Consider bike trips less than 100 minutes as the checkout time is 30 minutes, so this is double the allotted time.
citibike %>%
  filter(trip.duration < 100) %>% # only consider trips less than 100 minutes. 
  ggplot(aes(x=trip.duration)) +
  geom_histogram(bins=100) +
  labs(x = 'Trip Duration (min.)',
       y = 'Number of Trips')

```

As expected, most trips are below 30 minutes and the graph is left skewed, indicating a higher volume of short trip durations.

```{r}
# Segment durations by user type
citibike %>%
  filter(trip.duration < 100) %>%
  ggplot(aes(x=trip.duration)) +
  geom_histogram(bins=100) +
  labs(x = 'Trip Duration (min.)',
       y = 'Number of Trips') +
  facet_wrap(~member_casual)
```

```{r}
# Same as above with density plot instead of histogram
citibike %>%
  filter(trip.duration < 100) %>%
  ggplot(aes(x=trip.duration, fill=member_casual)) +
  geom_density(alpha=0.2) +
  labs(x = 'Trip Duration (min.)',
       y = 'Number of Trips')
  
```

Casual do tend to have longer trips

```{r}
citibike %>%
  group_by(start.hour) %>%
  summarize(med.duration=median(trip.duration)) %>%
  ggplot(aes(x=start.hour, y=med.duration)) +
  geom_point() +
  geom_line(aes(group=1), linetype='dotted')
```

```{r}
citibike %>%
  group_by(weekday, start.hour) %>%
  summarize(med.duration=median(trip.duration)) %>%
  ggplot(aes(x=start.hour, y=med.duration, group=weekday, color=weekday)) +
  geom_point(size=3) +
  geom_line(size=0.5) +
  facet_wrap(~weekday, nrow=1) +
  theme(legend.position='none') +
  scale_x_discrete(breaks=c(0,3,6,9,12,15,18,21))
```

```{r}
citibike %>%
  filter(member_casual %in% c('member', 'casual')) %>%
  group_by(weekday, start.hour, member_casual) %>%
  summarize(med.duration=median(trip.duration)) %>%
  ggplot(aes(x=start.hour, y=med.duration, group=weekday, color=weekday)) +
  geom_point(size=3) +
  geom_line(size=0.5) +
  facet_grid(weekday~member_casual) +
  theme(legend.position='none') +
  scale_x_discrete(breaks=c(0,3,6,9,12,15,18,21))
```

```{r}
citibike %>%
  filter(member_casual %in% c('member', 'casual')) %>%
  group_by(weekday, start.hour, member_casual) %>%
  summarize(med.duration=median(trip.duration)) %>%
  ggplot(aes(x=start.hour, y=med.duration, group=member_casual, 
             color=member_casual, linetype=member_casual, shape=member_casual)) +
  geom_point(size=2) +
  geom_line(size=0.5) +
  facet_wrap(~weekday, nrow=1) +
  labs(x='Time of Day',
       y='Median Trip Duration') +
  scale_x_discrete(breaks=c(0,6,12,18))
```

```{r}
# Ok, now I want to understand all the stations
n_distinct(citibike$start_station_id)

citibike %>%
  filter(startsWith(as.character(start_station_id), 'S'))
# Hmmm, there are 58 rows in the NYC district that start with 'SYS'
```

1618 start station IDs in NYC

```{r}
n_distinct(citibike$end_station_id)
```

And 1658 end station IDs in NYC

```{r}
setdiff(citibike$end_station_id, citibike$start_station_id)
```

Of those 40, there is a blank, which means abandoned, several JC (Jersey City), several HB (Hoboken), one number which should be a specific station in NYC, and 3 SYS*

```{r}
# Create table of start to end station IDs
stations_cols <- citibike %>%
  filter(trip.duration > 4) %>% # Only consider trips of a minimum 5 minutes
  select(start_station_id, end_station_id)
stations_table <- as.data.frame((table(stations_cols)))

stations_table <- stations_table %>%
  filter(Freq > 0)

stations_table_order <- stations_table[order(-stations_table$Freq),]

stations_table_order
```

For all valid combinations of start to end, there are 472920 combinations
By removing trips of <= 4, there's a total of 471130 combinations

The above table also indicates the frequency of those trips for start-end combinations.

The top 5 entries are the same start and end station ID. so these are casual rides, I have a feeling these 5 are near tourist destinations, perhaps Central Park

```{r}
stations_table_dif <- stations_table_order %>%
  filter(as.character(start_station_id) != as.character(end_station_id))

nrow(stations_table_dif)
```

469531 in which the start and the end station IDs are NOT the same

```{r}
tail(stations_table_dif, 200)
```

Now, I want to determine overall flow between any existing combination. At the end of the month, is the flow to or from a station

```{r}
stations_table_dif1 <- stations_table_dif
stations_table_dif2 <- stations_table_dif
```



```{r}
# Added all=TRUE to account for one-sided counts
res <- 
merge(stations_table_dif1, 
      stations_table_dif1, 
      by.x=c('start_station_id','end_station_id'), 
      by.y=c('end_station_id','start_station_id'), all = TRUE)
# Set the NA (one-sided trips) to count of 0
res[is.na(res)] <- 0
```

```{r}
res$surplus <- res$Freq.y - res$Freq.x
res <- res[order(-res$surplus),]
res
```

```{r}
# Remove rows with no start station id, those are a result of the merge all=TRUE and should not exist
# Also, remove all rows in which the start_station_id begins with an 'S'
res <- res %>% filter(start_station_id != '' & !startsWith(as.character(start_station_id), 'S'))
res
```

Above returns a list of 618,835 combinations given every start-end combo exists as the inverse, 

So Freq.x is the count of trips from start to end
-- Freq.y is the count of trips from end to start
surplus is Freq.y - Freq.x which means that positive number indicates return trips are more and thus surplus of bikes
and negative number indicates return trips are less and thus the station is not breaking even

```{r}
res %>% filter(end_station_id == '')
```

1350 rows indicate most start stations will have at least one abandoned bike

```{r}
res %>% filter(Freq.x == 0)
```

With Freq.x ==0 , there are 149336 rows in which an end-to-start occurs, so the rows are pure surplus to the start_station_id

```{r}
# Want to identify the surplus (or not) by station for the month
station_surplus_count <- res %>%
  group_by(start_station_id) %>%
  summarize(surplus_sum=sum(surplus))
station_surplus_count
```
The above indicates 1650 rows, 8 less than the count of end_station_id from the initial dataset

```{r}
station_surplus_count <- station_surplus_count[order(-station_surplus_count$surplus_sum),]
#station_surplus_count %>%
#    filter(startsWith(as.character(start_station_id), 'S'))
colnames(station_surplus_count)[1] <- "station_id"
station_surplus_count
```
21 start with J
14 start with H

Above is result showing the surplus(+) or not surplus (-) of 1650 stations in the NYC district, this probably includes a few JC or HB stations

```{r}
# Extract just the end station Id, lat, log
# because this had the higher count from the initial dataset, going with end_station_id
end_station_info <- citibike %>%
  select(end_station_id, end_lng, end_lat)

#end_station_info <- unique( end_station_info[ , 1:3 ] )
end_station_info <- end_station_info[!duplicated(end_station_info$end_station_id),]
end_station_info
```

```{r}
# Now I want the coordinates of all those station_ids
station_surplus_count_coords <- merge(x = station_surplus_count, y = end_station_info, by.x = 'station_id', by.y='end_station_id', all.x = TRUE)

colnames(station_surplus_count_coords)[3] <- "lng"
colnames(station_surplus_count_coords)[4] <- "lat"
station_surplus_count_coords
```
Above table accounts for all the station IDs with overal surplus or not surplus along with coordinates

now to try leaflet to color the station Ids

```{r}
library(leaflet)

```

```{r}

# Using basemaps for NYC
m <- leaflet(data=station_surplus_count_coords) %>% 
#  setView(zoom=12) %>%
  addTiles() %>%
  addCircleMarkers(
    ~lng, ~lat, 
    popup=~as.character(station_id), 
    label=~as.character(station_id), 
    radius=.5,
    color = ~ifelse(surplus_sum >= 1, 'blue', 
                    ifelse(surplus_sum == 0, 'green', 'red'))
  )

# Display map
m
```

Above map indicates the overall net bikes of a station for the given month
- blue, value is positive
- red, value is negative
- green, value is 0

```{r}
sum(station_surplus_count_coords$surplus_sum)
```


From the initial dataset, there were 3838 trips without an end lat/long, so that means bikes were abandoned
And doing the math 3838 * 2 the 7676, which is just 10 more than the negative number, so it seems I've included the abandoned in this surplus.

If the surplus is negative, this must account for the abandoned bikes, but why is the count double? I should set blank to ABAN so it's clear there's a value to it.

```{r}
station_surplus_count_coords %>%
  filter(surplus_sum > 0) %>%
  count()
```
826 stations with a surplus

```{r}
station_surplus_count_coords %>%
  filter(surplus_sum == 0) %>%
  count()
```
21 stations that break even

```{r}
station_surplus_count_coords %>%
  filter(surplus_sum < 0) %>%
  count()
```
803 stations with not surplus (overall result is less bikes)

```{r}
head(station_surplus_count)
```

```{r}

```

```{r}
# Now I want the coordinates of all those station_ids
station_surplus_count_coords <- merge(x = station_surplus_count, y = citibike, by.x = 'station_id', by.y='end_station_id', all.x = TRUE)
station_surplus_count_coords
```


```{r}
# Count of occurrences for each value in start_station_id
start_station_id_counts <- as.data.frame(table(citibike$start_station_id))

colnames(start_station_id_counts)[1] <- "start_station_id"
colnames(start_station_id_counts)[2] <- "start_count"
start_station_id_counts <- start_station_id_counts[order(-start_station_id_counts$start_count),]
start_station_id_counts
```

```{r}
# Count of occurrences for each value in end_station_id
as.data.frame(table(citibike$end_station_id))

end_station_id_counts <- as.data.frame(table(citibike$end_station_id))

colnames(end_station_id_counts)[1] <- "end_station_id"
colnames(end_station_id_counts)[2] <- "end_count"
end_station_id_counts <- end_station_id_counts[order(-end_station_id_counts$end_count),]
end_station_id_counts
```

```{r}
res <- merge(start_station_id_counts, end_station_id_counts, by.x=c('start_station_id'), by.y=c('end_station_id'))
colnames(res)[1] <- "station_id"
res$end_minus_start_cnt <- res$end_count - res$start_count
res <- res[order(-res$end_minus_start_cnt),]
res
```

Positive number indicates surplus by bikes
Negative number indicates bikes not being returned to a station

```{r}
min(citibike$started_at)
```

```{r}
# https://stackoverflow.com/questions/36827572/create-a-time-interval-of-15-minutes-from-minutely-data-in-r
citibike.start.count.by.station <- citibike %>% group_by(by15=cut(as.POSIXct(started_at), "15 min")) %>%
  dplyr::count(start_station_id, by15, sort=TRUE)

citibike.start.count.by.station
```

```{r}
citibike.end.count.by.station <- citibike %>% group_by(by15=cut(as.POSIXct(ended_at), mydateseq)) %>%
  dplyr::count(end_station_id, by15, sort=TRUE)

citibike.end.count.by.station
```

```{r}
station.count.by.15min <- 
  merge(citibike.start.count.by.station, citibike.end.count.by.station, by.x=c('by15', 'start_station_id'), by.y=c('by15', 'end_station_id'))

station.count.by.15min
```

```{r}
mydateseq<-seq(as.POSIXct("2022-09-01"), by="15 min", length.out = 2880)  

# Output the data sequence to confirm the result are 15 minute intervals which start on the hour
#mydateseq
```

```{r}
station.count.by.15min$diff <- station.count.by.15min$n.y - station.count.by.15min$n.x

station.count.by.15min
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

~~~~~

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```
